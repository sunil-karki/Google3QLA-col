{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google3QLA-col.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOCgdDeJo9reWSb9UuR9T7v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunil-karki/Google3QLA-col/blob/master/Google3QLA_COLAB_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoeMYW5MTbKu",
        "colab_type": "code",
        "outputId": "a3b3d64c-6f58-464a-c161-346090fbbe86",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db712426-5eed-4d1b-889b-3ef03dba94f2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-db712426-5eed-4d1b-889b-3ef03dba94f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample_submission.csv to sample_submission.csv\n",
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3ugdvSiUP5x",
        "colab_type": "code",
        "outputId": "2a0e440f-80d8-4909-bbd7-21ed0e5694b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "X_train = pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "#X_train = pd.read_csv(\"../input/google-quest-challenge/train.csv\")\n",
        "print( len(X_train.columns), ' ', len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41   6079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm1wMy4AWLFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjALbfArRS-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a9e4c609-f1b8-4c27-b8e3-b803bca5231b"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQHgNVExPyFi",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "a26bd839-b159-4b30-aff0-5d6b0b8936fe"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dc9b762e-f2d7-4fe7-8663-113b14693ec7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-dc9b762e-f2d7-4fe7-8663-113b14693ec7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"sunilkarki520\",\"key\":\"8368d7fdc07a580b54aeb9a6df65cda4\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRU8MxF_TvGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6S7wRZRULLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1861dcf9-18c2-4439-ae29-449f1895a246"
      },
      "source": [
        "!kaggle competitions download -c google-quest-challenge "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv to /content\n",
            "\r  0% 0.00/954k [00:00<?, ?B/s]\n",
            "100% 954k/954k [00:00<00:00, 64.4MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/4.50M [00:00<?, ?B/s]\n",
            "100% 4.50M/4.50M [00:00<00:00, 148MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/115k [00:00<?, ?B/s]\n",
            "100% 115k/115k [00:00<00:00, 92.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAEHVq1jVKT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51378123-c4fe-4de4-bd58-7305c9dc7235"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle_1.json  sample_data\t      test.csv\n",
            "kaggle.json    sample_submission.csv  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r75f3-INWhj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#df = pd.read_csv('filename.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "X_train = pd.read_csv('train.csv.zip', compression='zip')\n",
        "\n",
        "#X_train[['qa_id','question_title','question_body','question_user_name','question_user_page','answer','answer_user_name','answer_user_page','url',\n",
        "#        'category','host']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfa3tV7RcIec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao6QqRMJWaSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "338eecf5-5f20-405c-9bbb-3165bf37a7ee"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha-pEGA1ZpLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSFRFUDzZrZu",
        "colab_type": "code",
        "outputId": "07e3e9f8-c658-44e0-aa85-0ae48131737e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        }
      },
      "source": [
        "X_train[['qa_id','question_title','question_body','question_user_name','question_user_page','answer','answer_user_name','answer_user_page','url',\n",
        "        'category','host']]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>question_user_name</th>\n",
              "      <th>question_user_page</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_user_name</th>\n",
              "      <th>answer_user_page</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>host</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What am I losing when using extension tubes in...</td>\n",
              "      <td>After playing around with macro photography on...</td>\n",
              "      <td>ysap</td>\n",
              "      <td>https://photo.stackexchange.com/users/1024</td>\n",
              "      <td>I just got extension tubes, so here's the skin...</td>\n",
              "      <td>rfusca</td>\n",
              "      <td>https://photo.stackexchange.com/users/1917</td>\n",
              "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>photo.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the distinction between a city and a s...</td>\n",
              "      <td>I am trying to understand what kinds of places...</td>\n",
              "      <td>russellpierce</td>\n",
              "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
              "      <td>It might be helpful to look into the definitio...</td>\n",
              "      <td>Erik Schmidt</td>\n",
              "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
              "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>rpg.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Maximum protusion length for through-hole comp...</td>\n",
              "      <td>I'm working on a PCB that has through-hole com...</td>\n",
              "      <td>Joe Baker</td>\n",
              "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
              "      <td>Do you even need grooves?  We make several pro...</td>\n",
              "      <td>Dwayne Reid</td>\n",
              "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
              "      <td>http://electronics.stackexchange.com/questions...</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>electronics.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Can an affidavit be used in Beit Din?</td>\n",
              "      <td>An affidavit, from what i understand, is basic...</td>\n",
              "      <td>Scimonster</td>\n",
              "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
              "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
              "      <td>Y     e     z</td>\n",
              "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
              "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>judaism.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How do you make a binary image in Photoshop?</td>\n",
              "      <td>I am trying to make a binary image. I want mor...</td>\n",
              "      <td>leigero</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
              "      <td>q2ra</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>graphicdesign.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6074</th>\n",
              "      <td>9642</td>\n",
              "      <td>Using a ski helmet for winter biking</td>\n",
              "      <td>I am curious if anyone uses a skiing helmet fo...</td>\n",
              "      <td>sixtyfootersdude</td>\n",
              "      <td>https://bicycles.stackexchange.com/users/134</td>\n",
              "      <td>If you're thinking about wearing a ski helmet ...</td>\n",
              "      <td>Matt Leo</td>\n",
              "      <td>https://bicycles.stackexchange.com/users/3340</td>\n",
              "      <td>http://bicycles.stackexchange.com/questions/99...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>bicycles.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6075</th>\n",
              "      <td>9643</td>\n",
              "      <td>Adjustment to road bike brakes for high grade ...</td>\n",
              "      <td>I have a road bike with a front brake that wea...</td>\n",
              "      <td>ash</td>\n",
              "      <td>https://bicycles.stackexchange.com/users/14519</td>\n",
              "      <td>\\nYou can replace the pads (as stated elsewher...</td>\n",
              "      <td>Daniel R Hicks</td>\n",
              "      <td>https://bicycles.stackexchange.com/users/1584</td>\n",
              "      <td>http://bicycles.stackexchange.com/questions/25...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>bicycles.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6076</th>\n",
              "      <td>9645</td>\n",
              "      <td>Suppress 'file truncated' messages when using ...</td>\n",
              "      <td>I'm tailing a log file using tail -f messages....</td>\n",
              "      <td>Maneating Koala</td>\n",
              "      <td>https://unix.stackexchange.com/users/60445</td>\n",
              "      <td>Maybe help if can be fixes origin of this erro...</td>\n",
              "      <td>BG Bruno</td>\n",
              "      <td>https://unix.stackexchange.com/users/68208</td>\n",
              "      <td>http://unix.stackexchange.com/questions/169054...</td>\n",
              "      <td>TECHNOLOGY</td>\n",
              "      <td>unix.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6077</th>\n",
              "      <td>9646</td>\n",
              "      <td>When should a supervisor be a co-author?</td>\n",
              "      <td>What are people's views on this?  To be specif...</td>\n",
              "      <td>MrB</td>\n",
              "      <td>https://mathoverflow.net/users/2189</td>\n",
              "      <td>As a non-mathematician, I am somewhat mystifie...</td>\n",
              "      <td>angela</td>\n",
              "      <td>https://mathoverflow.net/users/4267</td>\n",
              "      <td>http://mathoverflow.net/questions/57337</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>mathoverflow.net</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6078</th>\n",
              "      <td>9647</td>\n",
              "      <td>Why are there so many different types of screw...</td>\n",
              "      <td>Newbie question.\\n\\nWhy is it that there's a b...</td>\n",
              "      <td>Doug T.</td>\n",
              "      <td>https://diy.stackexchange.com/users/321</td>\n",
              "      <td>First, I really like Eric's answer for practic...</td>\n",
              "      <td>Scivitri</td>\n",
              "      <td>https://diy.stackexchange.com/users/113</td>\n",
              "      <td>http://diy.stackexchange.com/questions/2701/wh...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>diy.stackexchange.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6079 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      qa_id  ...                             host\n",
              "0         0  ...          photo.stackexchange.com\n",
              "1         1  ...            rpg.stackexchange.com\n",
              "2         2  ...    electronics.stackexchange.com\n",
              "3         3  ...        judaism.stackexchange.com\n",
              "4         5  ...  graphicdesign.stackexchange.com\n",
              "...     ...  ...                              ...\n",
              "6074   9642  ...       bicycles.stackexchange.com\n",
              "6075   9643  ...       bicycles.stackexchange.com\n",
              "6076   9645  ...           unix.stackexchange.com\n",
              "6077   9646  ...                 mathoverflow.net\n",
              "6078   9647  ...            diy.stackexchange.com\n",
              "\n",
              "[6079 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjDLHJ-TZrw_",
        "colab_type": "code",
        "outputId": "8a3fa0d8-b249-4508-86b9-6cc502098053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "X_train[['qa_id','question_title','question_body','answer','category']]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>answer</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What am I losing when using extension tubes in...</td>\n",
              "      <td>After playing around with macro photography on...</td>\n",
              "      <td>I just got extension tubes, so here's the skin...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the distinction between a city and a s...</td>\n",
              "      <td>I am trying to understand what kinds of places...</td>\n",
              "      <td>It might be helpful to look into the definitio...</td>\n",
              "      <td>CULTURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Maximum protusion length for through-hole comp...</td>\n",
              "      <td>I'm working on a PCB that has through-hole com...</td>\n",
              "      <td>Do you even need grooves?  We make several pro...</td>\n",
              "      <td>SCIENCE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Can an affidavit be used in Beit Din?</td>\n",
              "      <td>An affidavit, from what i understand, is basic...</td>\n",
              "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
              "      <td>CULTURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How do you make a binary image in Photoshop?</td>\n",
              "      <td>I am trying to make a binary image. I want mor...</td>\n",
              "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6074</th>\n",
              "      <td>9642</td>\n",
              "      <td>Using a ski helmet for winter biking</td>\n",
              "      <td>I am curious if anyone uses a skiing helmet fo...</td>\n",
              "      <td>If you're thinking about wearing a ski helmet ...</td>\n",
              "      <td>CULTURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6075</th>\n",
              "      <td>9643</td>\n",
              "      <td>Adjustment to road bike brakes for high grade ...</td>\n",
              "      <td>I have a road bike with a front brake that wea...</td>\n",
              "      <td>\\nYou can replace the pads (as stated elsewher...</td>\n",
              "      <td>CULTURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6076</th>\n",
              "      <td>9645</td>\n",
              "      <td>Suppress 'file truncated' messages when using ...</td>\n",
              "      <td>I'm tailing a log file using tail -f messages....</td>\n",
              "      <td>Maybe help if can be fixes origin of this erro...</td>\n",
              "      <td>TECHNOLOGY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6077</th>\n",
              "      <td>9646</td>\n",
              "      <td>When should a supervisor be a co-author?</td>\n",
              "      <td>What are people's views on this?  To be specif...</td>\n",
              "      <td>As a non-mathematician, I am somewhat mystifie...</td>\n",
              "      <td>SCIENCE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6078</th>\n",
              "      <td>9647</td>\n",
              "      <td>Why are there so many different types of screw...</td>\n",
              "      <td>Newbie question.\\n\\nWhy is it that there's a b...</td>\n",
              "      <td>First, I really like Eric's answer for practic...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6079 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      qa_id  ...    category\n",
              "0         0  ...   LIFE_ARTS\n",
              "1         1  ...     CULTURE\n",
              "2         2  ...     SCIENCE\n",
              "3         3  ...     CULTURE\n",
              "4         5  ...   LIFE_ARTS\n",
              "...     ...  ...         ...\n",
              "6074   9642  ...     CULTURE\n",
              "6075   9643  ...     CULTURE\n",
              "6076   9645  ...  TECHNOLOGY\n",
              "6077   9646  ...     SCIENCE\n",
              "6078   9647  ...   LIFE_ARTS\n",
              "\n",
              "[6079 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52XGcjKOZr_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train['question_body'][0]\n",
        "##  https://www.figure-eight.com/data-for-everyone/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLtx9636ZsGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'question_title','question_body','category' to be added together here\n",
        "X_train['question_body'] = X_train['question_body'] + ' ' + X_train['question_title'] + ' ' + X_train['category']\n",
        "del X_train['question_title']\n",
        "del X_train['category']\n",
        "#X_train['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vgMr6bZZsNc",
        "colab_type": "code",
        "outputId": "f1777b2c-1e06-4095-ca60-38cd3851c5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['qa_id', 'question_body', 'question_user_name', 'question_user_page',\n",
              "       'answer', 'answer_user_name', 'answer_user_page', 'url', 'host',\n",
              "       'question_asker_intent_understanding', 'question_body_critical',\n",
              "       'question_conversational', 'question_expect_short_answer',\n",
              "       'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
              "       'question_interestingness_others', 'question_interestingness_self',\n",
              "       'question_multi_intent', 'question_not_really_a_question',\n",
              "       'question_opinion_seeking', 'question_type_choice',\n",
              "       'question_type_compare', 'question_type_consequence',\n",
              "       'question_type_definition', 'question_type_entity',\n",
              "       'question_type_instructions', 'question_type_procedure',\n",
              "       'question_type_reason_explanation', 'question_type_spelling',\n",
              "       'question_well_written', 'answer_helpful',\n",
              "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
              "       'answer_satisfaction', 'answer_type_instructions',\n",
              "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
              "       'answer_well_written'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY2WNVKzcojV",
        "colab_type": "code",
        "outputId": "66a09395-d532-42d3-f2b4-1c00bbdf66c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "#Resource stopwords and wordnet not found\n",
        "#needed to do this below in colab\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCmqLbVeZsYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import nltk\n",
        "import re\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "lm = nltk.WordNetLemmatizer()\n",
        "st = nltk.PorterStemmer()\n",
        "\n",
        "class NLP_preprocess:\n",
        "    def tokenize(self, text):\n",
        "        tokens = re.split('\\W+', text)\n",
        "        return tokens\n",
        "\n",
        "    def remove_stopwords(self, tokenized_text):\n",
        "        text = [word for word in tokenized_text if word not in stopword]\n",
        "        return text\n",
        "    \n",
        "    def lemmatizing(self, text):\n",
        "        text = [lm.lemmatize(word) for word in text]\n",
        "        return text\n",
        "    \n",
        "    def stemming(self, text):\n",
        "        text = [st.stem(word) for word in text]\n",
        "        return text\n",
        "\n",
        "    def process_column(self, col):\n",
        "        col = col.apply(lambda x: self.tokenize(x.lower()))\n",
        "        col = col.apply(lambda x: self.remove_stopwords(x))\n",
        "        col = col.apply(lambda x: self.lemmatizing(x))\n",
        "        return col\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXhrAtQVZsnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = NLP_preprocess()\n",
        "\n",
        "#Contains column which are text. Needs to be converted to Token\n",
        "list_col = ['answer', 'question_body']\n",
        "\n",
        "for col in list_col:\n",
        "    X_train[col] = nlp.process_column(X_train[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4c5T5eXZsvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLP_columns:\n",
        "    def join_col(self, list_col):\n",
        "        new_col = X_train[list_col[0]]\n",
        "    \n",
        "        for col in list_col[1:]:\n",
        "            new_col += X_train[col]\n",
        "        \n",
        "        return new_col\n",
        "\n",
        "    #Removing unnecessary elements from the processes joined Tokenized column\n",
        "    def remove_values_from_list(self, the_list, val):\n",
        "        return [value for value in the_list if value != val]\n",
        "    \n",
        "    def remove_values_from_column(self, col, val):\n",
        "        return col.apply(lambda row: self.remove_values_from_list(row, val))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-nEcdCtZtCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKdZljSDZtSR",
        "colab_type": "code",
        "outputId": "5edd5d82-3cb9-4e88-9ba7-0b06f93fc3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "def process_vocab():\n",
        "    vocab = set()\n",
        "    for a in X_train['answer']:\n",
        "        vocab = vocab.union(set(a))\n",
        "\n",
        "    for a in X_train['question_body']:\n",
        "        vocab = vocab.union(set(a))\n",
        "    \n",
        "    vocab_len = len(vocab)\n",
        "    #print(vocab_len)      #49474\n",
        "    return vocab_len\n",
        "    \n",
        "vocab_len = process_vocab()\n",
        "print(vocab_len)\n",
        "'''"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef process_vocab():\\n    vocab = set()\\n    for a in X_train['answer']:\\n        vocab = vocab.union(set(a))\\n\\n    for a in X_train['question_body']:\\n        vocab = vocab.union(set(a))\\n    \\n    vocab_len = len(vocab)\\n    #print(vocab_len)      #49474\\n    return vocab_len\\n    \\nvocab_len = process_vocab()\\nprint(vocab_len)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv6rURb3ZtbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(vocab)\n",
        "ylabels = ['question_asker_intent_understanding','question_body_critical','question_conversational','question_expect_short_answer',\n",
        "'question_fact_seeking','question_has_commonly_accepted_answer','question_interestingness_others','question_interestingness_self',\n",
        "'question_multi_intent','question_not_really_a_question','question_opinion_seeking','question_type_choice','question_type_compare',\n",
        "'question_type_consequence','question_type_definition','question_type_entity','question_type_instructions','question_type_procedure',\n",
        "'question_type_reason_explanation','question_type_spelling','question_well_written','answer_helpful','answer_level_of_information',\n",
        "'answer_plausible','answer_relevance','answer_satisfaction','answer_type_instructions','answer_type_procedure','answer_type_reason_explanation',\n",
        "'answer_well_written']\n",
        "\n",
        "y = X_train[ylabels].astype(np.int64)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjU4CptRZtf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Delete unwanted columns from X_train\n",
        "#del X_train['question_asker_intent_understanding']\n",
        "#X_train.drop(['question_asker_intent_understanding', 'question_body_critical'], axis=1, inplace=True)\n",
        "X_train.drop(ylabels, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_824VeoZtuC",
        "colab_type": "code",
        "outputId": "19f8dd3d-c091-41a5-f070-85b4da9ccb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_train.columns     #Will need only  'answer' 'question_body'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['qa_id', 'question_body', 'question_user_name', 'question_user_page',\n",
              "       'answer', 'answer_user_name', 'answer_user_page', 'url', 'host'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0rQn13wZt1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.33, random_state=np.random, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65yXNytGZt6l",
        "colab_type": "code",
        "outputId": "4e9bbb15-4702-4330-ae5e-12ba3446d490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2007, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSiTz4XiZtyJ",
        "colab_type": "code",
        "outputId": "4f8e436a-b69a-4b42-9497-3dabbedbba5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = np.arange(20).reshape((10, 2)), range(10)\n",
        "print(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=np.random, shuffle=True)\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "'''"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.model_selection import train_test_split\\nX, y = np.arange(20).reshape((10, 2)), range(10)\\nprint(X)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=np.random, shuffle=True)\\nprint(X_train)\\nprint(y_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zALW7UDrZtq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLP_before_model:\n",
        "    tokenizer = 0\n",
        "    max_question_body_len = 0\n",
        "    max_answers_seq_len = 0\n",
        "    train_question_body = []\n",
        "    train_answers = []\n",
        "    \n",
        "    x_answer = 0\n",
        "    x_question = 0\n",
        "    \n",
        "    vocab = set()\n",
        "    vocab_len = 0\n",
        "    \n",
        "    def __init__(self, x_answer, x_question):\n",
        "        self.x_answer = x_answer\n",
        "        self.x_question = x_question\n",
        "        \n",
        "        self.process_vocab()\n",
        "        self.tokenizer = Tokenizer(filters = [])\n",
        "        self.tokenizer.fit_on_texts(self.vocab)\n",
        "        \n",
        "        #self.process_for_model()\n",
        "        \n",
        "    def process_vocab(self):\n",
        "        #vocab = set()\n",
        "        for a in self.x_answer:\n",
        "            self.vocab = self.vocab.union(set(a))\n",
        "\n",
        "        for a in self.x_question:\n",
        "            self.vocab = self.vocab.union(set(a))\n",
        "\n",
        "        self.vocab_len = len(self.vocab)\n",
        "        #print(vocab_len)      #49474\n",
        "        #return self.vocab_len\n",
        "        \n",
        "    def process_for_model(self):\n",
        "        for a in self.x_answer:\n",
        "            self.train_answers.append(a)\n",
        "\n",
        "        for a in self.x_question:\n",
        "            self.train_question_body.append(a)\n",
        "            \n",
        "        a, b = self.process_vectorize(self.train_answers, self.train_question_body)\n",
        "        return a, b\n",
        "                    \n",
        "    def process_vectorize(self, train_answers, train_question_body):\n",
        "        \n",
        "        train_answers_seq = self.tokenizer.texts_to_sequences(train_answers)\n",
        "        train_question_body_seq = self.tokenizer.texts_to_sequences(train_question_body)\n",
        "\n",
        "        self.max_question_body_len = max([len(data) for data in train_question_body_seq])        \n",
        "        self.max_answers_seq_len = max([len(data) for data in train_answers_seq])\n",
        "        \n",
        "        input_answer = pad_sequences(train_answers_seq, maxlen = self.max_answers_seq_len)\n",
        "        input_question = pad_sequences(train_question_body_seq, maxlen = self.max_question_body_len)\n",
        "\n",
        "        return input_answer, input_question\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_0jsrnWZtoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlpbefore_mdl = NLP_before_model(X_train['answer'], X_train['question_body'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ0n_PIeZtl5",
        "colab_type": "code",
        "outputId": "08c241b3-cb2d-4808-858f-db04fbd28a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Vectorize trrain data\n",
        "train_input_answer, train_input_question = nlpbefore_mdl.process_for_model()   #To vectorize only\n",
        "train_input_answer"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,  3388,  6935,  2891],\n",
              "       [    0,     0,     0, ..., 18286, 15314,  1624],\n",
              "       [    0,     0,     0, ...,  7949,  3281,  2422],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,  8578, 32133, 24924],\n",
              "       [    0,     0,     0, ...,  6869, 32414,  8645],\n",
              "       [    0,     0,     0, ...,   742, 35514, 11705]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiGuhNs5ZtZJ",
        "colab_type": "code",
        "outputId": "7f29f00d-56a5-47b6-e097-2f1281b138d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_answers_seq_len = nlpbefore_mdl.max_answers_seq_len\n",
        "max_question_body_len = nlpbefore_mdl.max_question_body_len\n",
        "vocab_len = nlpbefore_mdl.vocab_len\n",
        "print(max_answers_seq_len)\n",
        "print(max_question_body_len)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1346\n",
            "1832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMfvK5QeZtWf",
        "colab_type": "code",
        "outputId": "96f39ab2-37ea-45bd-c9fc-35c74e3d040f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Vectorize test data\n",
        "test_input_answer, test_input_question = nlpbefore_mdl.process_vectorize(X_test['answer'], X_test['question_body'])\n",
        "test_input_answer"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ..., 12066,  6587, 16872],\n",
              "       [    0,     0,     0, ...,  3866, 20833,  1441],\n",
              "       [    0,     0,     0, ...,  4560, 14593, 25704],\n",
              "       ...,\n",
              "       [    0,     0,     0, ..., 13489,  8182, 15958],\n",
              "       [    0,     0,     0, ..., 32996, 17089, 34325],\n",
              "       [    0,     0,     0, ..., 33131, 37362, 13178]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY_yyZqnZtQH",
        "colab_type": "code",
        "outputId": "7b11c7e0-59c7-4890-a013-aacab4c75e21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "max_answers_seq_len = nlpbefore_mdl.max_answers_seq_len\n",
        "max_question_body_len = nlpbefore_mdl.max_question_body_len\n",
        "vocab_len = nlpbefore_mdl.vocab_len\n",
        "print(max_answers_seq_len)\n",
        "print(max_question_body_len)\n",
        "'''"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmax_answers_seq_len = nlpbefore_mdl.max_answers_seq_len\\nmax_question_body_len = nlpbefore_mdl.max_question_body_len\\nvocab_len = nlpbefore_mdl.vocab_len\\nprint(max_answers_seq_len)\\nprint(max_question_body_len)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKuAF26QZtOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocablen = nlpbefore_mdl.process_vocab()\n",
        "#print(vocablen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbomHc5CZtM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrH_IqHVZtLb",
        "colab_type": "code",
        "outputId": "ba876401-f0d8-40fb-dabd-1b278b44fc1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(max_answers_seq_len)\n",
        "print(max_question_body_len)\n",
        "print(vocab_len)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1346\n",
            "1832\n",
            "40405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vppldq9gZtIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLP_model():\n",
        "    max_answers_seq_len = 0\n",
        "    max_question_body_len = 0\n",
        "    vocab_len = 0\n",
        "    \n",
        "    model = 0\n",
        "    history = 0\n",
        "    a = 0\n",
        "    \n",
        "    \n",
        "    def __init__(self, max_answers_seq_len, max_question_body_len, vocab_len):\n",
        "        self.max_answers_seq_len = max_answers_seq_len\n",
        "        self.max_question_body_len = max_question_body_len\n",
        "        self.vocab_len = vocab_len\n",
        "    \n",
        "    def create_model(self):\n",
        "        input_sequence = Input((self.max_answers_seq_len,)) #As we dont know batch size yet\n",
        "        question = Input((self.max_question_body_len,))\n",
        "\n",
        "        #Create input encoder M\n",
        "        input_encoder_m = Sequential()\n",
        "        input_encoder_m.add(Embedding(input_dim = self.vocab_len,output_dim = 64)) #From paper\n",
        "        input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "        #Create input encoder C:\n",
        "        input_encoder_c = Sequential()\n",
        "        input_encoder_c.add(Embedding(input_dim = self.vocab_len,output_dim = self.max_question_body_len)) #From paper\n",
        "        input_encoder_c.add(Dropout(0.3))\n",
        "\n",
        "        #Create question encoder:\n",
        "        question_encoder = Sequential()\n",
        "        question_encoder.add(Embedding(input_dim = self.vocab_len,output_dim = 64,input_length = self.max_question_body_len)) #From paper\n",
        "        question_encoder.add(Dropout(0.3))\n",
        "\n",
        "        input_encoded_m = input_encoder_m(input_sequence)\n",
        "        input_encoded_c = input_encoder_c(input_sequence)\n",
        "        question_encoded = question_encoder(question)\n",
        "\n",
        "        match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
        "        match = Activation('softmax')(match)\n",
        "\n",
        "        response = add([match,input_encoded_c])\n",
        "        response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input\n",
        "\n",
        "        answer = concatenate([response, question_encoded])\n",
        "\n",
        "        # Reduce the answer tensor with a RNN (LSTM)\n",
        "        answer = LSTM(32)(answer)\n",
        "\n",
        "        #Regularization with dropout:\n",
        "        answer = Dropout(0.5)(answer)\n",
        "        #Output layer:\n",
        "        answer = Dense(30)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s\n",
        "\n",
        "        #Now we need to output a probability distribution for the vocab, using softmax:\n",
        "        answer = Activation('softmax')(answer)\n",
        "\n",
        "        #Now we build the final model:\n",
        "        self.model = Model([input_sequence,question], answer)\n",
        "\n",
        "    def compile_model(self):\n",
        "        ##sgd = optimizers.SGD(lr=0.2, decay=1e-5, momentum=0.7, nesterov=True)  #0.01\n",
        "\n",
        "        ##self.model.compile(loss='mean_squared_error', optimizer=sgd, metrics = ['accuracy'])\n",
        "        \n",
        "        #model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        #model.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "        #model.compile(optimizer='rmsprop', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "        # model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        #Categorical instead of binary cross entropy as because of the way we are training\n",
        "        #we could actually see any of the words from the vocab as output\n",
        "        #however, we should only see yes or no\n",
        "\n",
        "        ## self.model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy']) #acc 6%\n",
        "        self.model.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy']) #accuracy around 75%\n",
        "        \n",
        "    def summary_model(self):\n",
        "        self.model.summary()\n",
        "        \n",
        "    def fit_model(self, input_labels, input_answer, input_question):\n",
        "        #self.a = input_labels.astype(np.int64)\n",
        "        #input_train == answeer  answert train == label // label left tot do\n",
        "        #  history = model.fit([inputs_train,questions_train],a, batch_size = 32, epochs = 1000, validation_data = ([inputs_test,questions_test],answers_test))\n",
        "        \n",
        "        #print(type(self.a))\n",
        "        #self.history = self.model.fit([input_answer,input_question], a, batch_size = 50, epochs = 1000)\n",
        "        \n",
        "        #self.history = self.model.fit([input_answer,input_question], input_labels, batch_size = 75, epochs = 1500)\n",
        "        \n",
        "        self.history = self.model.fit([input_answer,input_question], input_labels, batch_size = 75, epochs = 1000)\n",
        "        #xxxxx\n",
        "        \n",
        "    def eval_model(self, answer, question):\n",
        "        pred_results = self.model.predict(([answer,question]))\n",
        "        \n",
        "    def save_model(self):\n",
        "        filename = 'google3qla.h5'\n",
        "        self.model.save(filename)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_aypHp5Zs_Z",
        "colab_type": "code",
        "outputId": "3b2a88bf-d9bf-4352-c4cf-e1b66296bbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "nlpmodel = NLP_model(max_answers_seq_len, max_question_body_len, vocab_len)\n",
        "nlpmodel.create_model()\n",
        "nlpmodel.compile_model()\n",
        "nlpmodel.summary_model()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 1346)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1832)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       multiple             2585920     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_6 (Sequential)       (None, 1832, 64)     2585920     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_2 (Dot)                     (None, 1346, 1832)   0           sequential_4[1][0]               \n",
            "                                                                 sequential_6[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1346, 1832)   0           dot_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       multiple             74021960    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 1346, 1832)   0           activation_3[0][0]               \n",
            "                                                                 sequential_5[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 1832, 1346)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1832, 1410)   0           permute_2[0][0]                  \n",
            "                                                                 sequential_6[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 32)           184704      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32)           0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 30)           990         dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 30)           0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 79,379,494\n",
            "Trainable params: 79,379,494\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmLRk79gZs9A",
        "colab_type": "code",
        "outputId": "def88852-9270-402f-cb48-3b4bed19867d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "nlpmodel.fit_model(y_train, train_input_answer, train_input_question)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "4072/4072 [==============================] - 537s 132ms/step - loss: 0.7473 - acc: 0.7626\n",
            "Epoch 2/1000\n",
            "4072/4072 [==============================] - 533s 131ms/step - loss: 0.7130 - acc: 0.7626\n",
            "Epoch 3/1000\n",
            "3375/4072 [=======================>......] - ETA: 1:31 - loss: 0.6958 - acc: 0.7638"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu_1lJtRZs6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(train_input_answer.shape)\n",
        "nlpmodel.save_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPAu5e7DZs4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "ld_model = load_model('google3qla.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga9ZaireZs2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y = np.zeros([2007, train_input_answer.shape[1] - test_input_answer.shape[1] ], dtype = int) #2007 is number of rows and 742 is column needed to match with train_answer\n",
        "test_input_answer_1 = np.append(test_input_answer, y, axis=1)\n",
        "\n",
        "print(test_input_answer_1.shape)\n",
        "print(train_input_answer.shape)\n",
        "\n",
        "y = np.zeros([2007, train_input_question.shape[1] - test_input_question.shape[1] ], dtype = int) #2007 is number of rows and 390 is column needed to match with train_question\n",
        "test_input_question_1 = np.append(test_input_question, y, axis=1)\n",
        "\n",
        "print(test_input_question_1.shape)\n",
        "print(train_input_question.shape)\n",
        "\n",
        "score = ld_model.evaluate([test_input_answer_1, test_input_question_1], y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhSnjHwAZszc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_test.shape)\n",
        "print(test_input_answer.shape)\n",
        "print(train_input_answer.shape)\n",
        "print(type(test_input_answer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9iKYa9BZstm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_input_question.shape)\n",
        "print(train_input_question.shape)\n",
        "print(type(test_input_question))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWA1l7ayZsrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z_GSzPuZslC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFUstq_oZsjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###   Rough Work  ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wtKGE2MZsiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "ylabels = ['question_asker_intent_understanding','question_body_critical','question_conversational','question_expect_short_answer',\n",
        "'question_fact_seeking','question_has_commonly_accepted_answer','question_interestingness_others','question_interestingness_self',\n",
        "'question_multi_intent','question_not_really_a_question','question_opinion_seeking','question_type_choice','question_type_compare',\n",
        "'question_type_consequence','question_type_definition','question_type_entity','question_type_instructions','question_type_procedure',\n",
        "'question_type_reason_explanation','question_type_spelling','question_well_written','answer_helpful','answer_level_of_information',\n",
        "'answer_plausible','answer_relevance','answer_satisfaction','answer_type_instructions','answer_type_procedure','answer_type_reason_explanation',\n",
        "'answer_well_written']\n",
        "\n",
        "a = X_train[ylabels].astype(np.int64)\n",
        "nlpmodel.fit_model(a, input_answer, input_question)\n",
        "#nlpmodel.fit_model(X_train[ylabels])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvtDU7A7ZseT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def process_model_ready():\n",
        "    tokenizer = Tokenizer(filters = [])\n",
        "    tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "    train_question_body = []\n",
        "    train_answers = []\n",
        "\n",
        "    for a in X_train['answer']:\n",
        "        train_answers.append(a)\n",
        "\n",
        "    for a in X_train['question_body']:\n",
        "        train_question_body.append(a)\n",
        "\n",
        "    train_answers_seq = tokenizer.texts_to_sequences(train_answers)\n",
        "    train_question_body_seq = tokenizer.texts_to_sequences(train_question_body)\n",
        "\n",
        "    max_question_body_len = max([len(data) for data in train_question_body_seq])\n",
        "    print(max_question_body_len)\n",
        "\n",
        "    max_answers_seq_len = max([len(data) for data in train_answers_seq])\n",
        "    print(max_answers_seq_len)\n",
        "\n",
        "    input_answer = pad_sequences(train_answers_seq, maxlen=max_answers_seq_len)\n",
        "    input_question = pad_sequences(train_question_body_seq, maxlen=max_question_body_len)\n",
        "    \n",
        "    return input_answer\n",
        "\n",
        "input_answer = process_model_ready()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E09pxAI5ZsWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "input_sequence = Input((max_answers_seq_len,)) #As we dont know batch size yet\n",
        "question = Input((max_question_body_len,))\n",
        "\n",
        "#Create input encoder M\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim = 64)) #From paper\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "#Create input encoder C:\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim = max_question_body_len)) #From paper\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "\n",
        "#Create question encoder:\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_len,output_dim = 64,input_length=max_question_body_len)) #From paper\n",
        "question_encoder.add(Dropout(0.3))\n",
        "\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
        "match = Activation('softmax')(match)\n",
        "\n",
        "response = add([match,input_encoded_c])\n",
        "response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input\n",
        "\n",
        "answer = concatenate([response, question_encoded])\n",
        "\n",
        "# Reduce the answer tensor with a RNN (LSTM)\n",
        "answer = LSTM(32)(answer)\n",
        "\n",
        "#Regularization with dropout:\n",
        "answer = Dropout(0.5)(answer)\n",
        "#Output layer:\n",
        "answer = Dense(2)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s\n",
        "\n",
        "#Now we need to output a probability distribution for the vocab, using softmax:\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "#Now we build the final model:\n",
        "model = Model([input_sequence,question], answer)\n",
        "\n",
        "from keras import optimizers\n",
        "sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)  #0.01\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=sgd, metrics = ['accuracy'])\n",
        "#model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "#model.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#model.compile(optimizer='rmsprop', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "# model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "#Categorical instead of binary cross entropy as because of the way we are training\n",
        "#we could actually see any of the words from the vocab as output\n",
        "#however, we should only see yes or no\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train['answer_well_written']\n",
        "#X_train.columns\n",
        "a = X_train[['answer_well_written','question_well_written']].astype(np.int64)\n",
        "a\n",
        "\n",
        "ylabels = ['question_asker_intent_understanding','question_body_critical','question_conversational','question_expect_short_answer',\n",
        "'question_fact_seeking','question_has_commonly_accepted_answer','question_interestingness_others','question_interestingness_self',\n",
        "'question_multi_intent','question_not_really_a_question','question_opinion_seeking','question_type_choice','question_type_compare',\n",
        "'question_type_consequence','question_type_definition','question_type_entity','question_type_instructions','question_type_procedure',\n",
        "'question_type_reason_explanation','question_type_spelling','question_well_written','answer_helpful','answer_level_of_information',\n",
        "'answer_plausible','answer_relevance','answer_satisfaction','answer_type_instructions','answer_type_procedure','answer_type_reason_explanation',\n",
        "'answer_well_written']\n",
        "\n",
        "b = X_train[ylabels].astype(np.int64)\n",
        "b\n",
        "\n",
        "#input_train == answeer  answert train == label // label left tot do\n",
        "#  history = model.fit([inputs_train,questions_train],a, batch_size = 32, epochs = 1000, validation_data = ([inputs_test,questions_test],answers_test))\n",
        "  history = model.fit([input_answer,input_question],a, batch_size = 50, epochs = 1000)\n",
        "  \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvI7wzUDZsUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egAxtgvDZsR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}